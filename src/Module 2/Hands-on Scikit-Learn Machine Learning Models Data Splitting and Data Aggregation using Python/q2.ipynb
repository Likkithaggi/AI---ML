{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Best Hyperparameters: {'classifier__max_depth': None, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5, 'classifier__n_estimators': 100}\n",
      "Cross-validation scores: [0.75977654 0.82022472 0.83707865 0.80898876 0.84831461]\n",
      "Mean CV Accuracy: 0.8149\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Step 1: Load the dataset directly from a URL\n",
    "url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Step 2: Feature engineering\n",
    "df['Title'] = df['Name'].apply(lambda x: x.split(',')[1].split('.')[0].strip())\n",
    "title_mapping = {'Mr': 0, 'Miss': 1, 'Mrs': 2, 'Master': 3, 'Dr': 4, 'Rev': 5, 'Major': 6, 'Col': 7, 'Mlle': 8, 'Countess': 9}\n",
    "df['Title'] = df['Title'].map(title_mapping).fillna(-1)\n",
    "\n",
    "df['Sex'] = df['Sex'].map({'male': 0, 'female': 1})\n",
    "\n",
    "df = pd.get_dummies(df, columns=['Embarked'], drop_first=True)\n",
    "df.drop(columns=['Name', 'Ticket', 'Cabin'], inplace=True)\n",
    "\n",
    "# Step 3: Prepare features and labels\n",
    "X = df.drop(columns=['Survived'])\n",
    "y = df['Survived']\n",
    "\n",
    "# Step 4: Define preprocessing pipeline\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = [col for col in X.columns if col not in numeric_features]\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features)\n",
    "    ])\n",
    "\n",
    "# Step 5: Full pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Step 6: Hyperparameter tuning\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [100, 200],\n",
    "    'classifier__max_depth': [None, 10, 20],\n",
    "    'classifier__min_samples_split': [2, 5],\n",
    "    'classifier__min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, verbose=1, n_jobs=-1)\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Step 7: Evaluation\n",
    "best_model = grid_search.best_estimator_\n",
    "cv_scores = cross_val_score(best_model, X, y, cv=5, scoring='accuracy')\n",
    "\n",
    "# Step 8: Output\n",
    "print(f\"Best Hyperparameters: {grid_search.best_params_}\")\n",
    "print(f\"Cross-validation scores: {cv_scores}\")\n",
    "print(f\"Mean CV Accuracy: {cv_scores.mean():.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
